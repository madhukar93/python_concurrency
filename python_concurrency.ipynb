{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Python concurrency story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concurrency\n",
    "\n",
    "[dictionary.com](http://www.dictionary.com/browse/concurrent)\n",
    "- occurring or existing simultaneously or side by side\n",
    "- acting in conjunction; cooperating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The free lunch is over\n",
    "- approaching the physical limits of Moore's Law.\n",
    "- processors not getting faster\n",
    "- way forward is to have MORE processors, not faster processors\n",
    "\n",
    "\n",
    "[The free lunch is over](http://www.gotw.ca/publications/concurrency-ddj.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cocurrency is the way forward\n",
    "- allows for scaling 'horizontally'\n",
    "- explains the sudden surge of interest in Erlang, Scala, Clojure and functional programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concurrency allows for some cool things\n",
    "- better resource utilization\n",
    "- handle web scale and big data\n",
    "- applications that are responsive, that feel real time\n",
    "GUI, games\n",
    "- model the real world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Waiters and tables\n",
    "- 5 tables\n",
    "- 1 waiter: who can take one order at a time\n",
    "- Customers(Table) think about the order for 4 seconds\n",
    "- Waiter takes down order in 1 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# sequential_waiter.py\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class Waiter(object):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def take_order(self):\n",
    "        time.sleep(1)\n",
    "\n",
    "class Table(object):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.order_taken = False\n",
    "        self.name = name\n",
    "    \n",
    "    def give_order(self, waiter):\n",
    "        print(f\"{self.name} is thinking about the order\")\n",
    "        time.sleep(4)\n",
    "        self.order_taken = True\n",
    "        waiter.take_order()\n",
    "        print(f\"{self.name} has given it's order to {waiter.name}\")\n",
    "\n",
    "tables = [Table(\"A\"), Table(\"B\"), Table(\"C\"), Table(\"D\"), Table(\"E\")]\n",
    "waiter = Waiter(\"John Doe\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "for table in tables:\n",
    "    table.give_order(waiter)\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"taking all orders took {elapsed_time.seconds} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# multithreaded example\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class Waiter(object):\n",
    "    lock = threading.Lock()\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def take_order(self):\n",
    "        with self.lock:  # TODO: queue example if adequate time\n",
    "        # waiter can take only one order at a time.\n",
    "        # Sleep does not block the entire Python process\n",
    "        # here context switch will happen to another thread\n",
    "        # so we have to lock so that the waiter isn't\n",
    "        # allowed to be at two tables at once\n",
    "            time.sleep(1)\n",
    "\n",
    "class Table(object):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.order_taken = False\n",
    "        self.name = name\n",
    "    \n",
    "    def give_order(self, waiter):\n",
    "        print(f\"{self.name} is thinking about the order\")\n",
    "        time.sleep(4)\n",
    "        self.order_taken = True\n",
    "        waiter.take_order()\n",
    "        print(f\"{self.name} has given it's order to {waiter.name}\")\n",
    "\n",
    "tables = [Table(\"A\"), Table(\"B\"), Table(\"C\"), Table(\"D\"), Table(\"E\")]\n",
    "waiter = Waiter(\"John Doe\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "threads = []\n",
    "for table in tables:\n",
    "    thread = threading.Thread(target=table.give_order, args=(waiter,))\n",
    "    # all tables start thinking about ordering\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()  # wait for all threads to finish\n",
    "    # otherwise execution will continue without waiting for threads\n",
    "    # to end, and we'll get elapsed time as 0.\n",
    "\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"took {elapsed_time.seconds} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency is not parallelism\n",
    "\n",
    "__concurrency__: Dealing with a lot at once, property of the solution (code)\n",
    "\n",
    "__parallelism__: Doing a lot at once, property of the runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why you should care\n",
    "- lets you to pick the right tool for the right job\n",
    "- python threads don't run parallely, you can still do concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading in python\n",
    "\n",
    "__Advantages__\n",
    "- excellent for speeding up blocking I/O bound programs\n",
    "- Scheduled preemptively\n",
    "- Lighter memory footprint than processes\n",
    "- Shared memory - faster communication\n",
    "\n",
    "__Disdavantages__\n",
    "- GIL means that we can't take advantages of multiple cores.\n",
    "- Context switch may happen whenever, have to synchronize access to critical section.\n",
    "- Hard to test and debug\n",
    "- Context switches are hardly free. Can see degradation in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!, I am thread Thread-1\n",
      "Hello, World!, I am thread Thread-2\n",
      "Hello, World!, I am thread Thread-3\n",
      "Hello, World!, I am thread Thread-4\n",
      "Hello, World!, I am thread Thread-5\n",
      "elapsed time 5 s\n"
     ]
    }
   ],
   "source": [
    "# sequential_client.py\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "for i in range(5):\n",
    "    print(requests.get(\"http://127.0.0.1:5000\").text)\n",
    "end_time = datetime.now()\n",
    "print(f\"elapsed time {(end_time - start_time).seconds} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threaded_client.py\n",
    "import threading\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "def make_request():\n",
    "    print(requests.get(\"http://127.0.0.1:5000\").text)\n",
    "\n",
    "threads = []    \n",
    "for i in range(5):\n",
    "    thread = threading.Thread(target=make_request)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"took {elapsed_time.seconds} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIL the good parts\n",
    "- Python has one global lock, on the entire interpreter instead of thousands of granular locks everywhere else.\n",
    "- GIL makes it easy to integrate non thread safe C libraries\n",
    "- Locking and unlocking is not free, previous attempts at removing the GIL has resulted in severe degradation of the performance of a single thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python's approach to parallelism - Don't DIY\n",
    "- To make use of all cores, python prescribes using multiple processes.\n",
    "- Utilizing multiple cores is left up to the OS (since processes are scheduled by the OS).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "\n",
    "\n",
    "__Advantages__:\n",
    "- Can workaround the GIL by spawning multiple processes.\n",
    "- That makes them better at CPU bound tasks\n",
    "- Crashing processes will not kill our entire program\n",
    "\n",
    "__Disadvantages__:\n",
    "- Require IPC to communicate between processes.\n",
    "- slower context switches.\n",
    "- more startup cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu_bound_sequential.py\n",
    "from datetime import datetime\n",
    "\n",
    "def cpu_bound_task():\n",
    "    [i for i in range(100000)]\n",
    "    return True\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(all([cpu_bound_task() for i in range(1000)]))\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"took {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu_bound_multithreaded.py\n",
    "from datetime import datetime\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "p = ThreadPool(4)\n",
    "def cpu_bound_task(*args):\n",
    "    [i for i in range(100000)]\n",
    "    return True\n",
    "start_time = datetime.now()\n",
    "print(all(p.map(cpu_bound_task, [i for i in range(1000)], 100)))\n",
    "p.close()\n",
    "p.join()\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"took {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu_bound_multiprocess.py\n",
    "from multiprocessing import Pool\n",
    "p = Pool(4)\n",
    "def cpu_bound_task(*args):\n",
    "    [i for i in range(100000)]\n",
    "    return True\n",
    "start_time = datetime.now()\n",
    "print(all(p.map(cpu_bound_task, [i for i in range(1000)], 100)))\n",
    "p.close()\n",
    "p.join()\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"took {elapsed_time}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async\n",
    "- cooperative scheduling - need explicit code to cause task switch.\n",
    "- Typically single threaded\n",
    "- Since you control when task switches occur, you don't need locks for synchronization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Advantages__:\n",
    "- very low cost, since no context switch. Incidentally they're cheaper than function calls. Cheaper switching mechanism among all techniques. People prefer this model to locking, \n",
    "- No cost of synchronization = less CPU consumption. Async servers > threaded servers. You can run many many more async tasks than threads.\n",
    "\n",
    "__disadvantages__:\n",
    "- Need code that gives up control\n",
    "- Need an event loop\n",
    "- Everything has to be non-blocking.\n",
    "- Need to learn a lot of new things - new syntax, new libraries(aysnc versions), eventloops, futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# async example\n",
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class Waiter(object):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def take_order(self):\n",
    "        # blocks thread, hence blocking the entire event loop.\n",
    "        time.sleep(1)\n",
    "\n",
    "class Table(object):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.order_taken = False\n",
    "        self.name = name\n",
    "\n",
    "    # async keyword defines a coroutine\n",
    "    async def give_order(self, waiter):\n",
    "        print(f\"{self.name} is thinking about the order\")\n",
    "        await asyncio.sleep(4)  # This is how we give up control\n",
    "        # Execution will resume after 4 s.\n",
    "        self.order_taken = True\n",
    "        waiter.take_order()\n",
    "        print(f\"{self.name} has given it's order to {waiter.name}\")\n",
    "\n",
    "tables = [Table(\"A\"), Table(\"B\"), Table(\"C\"), Table(\"D\"), Table(\"E\")]\n",
    "waiter = Waiter(\"John Doe\")\n",
    "\n",
    "eventloop = asyncio.get_event_loop()\n",
    "start_time = datetime.now()\n",
    "tasks = [eventloop.create_task(table.give_order(waiter))\n",
    "         for table in tables]\n",
    "await asyncio.wait(tasks)\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"taking all orders took {elapsed_time.seconds} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#async_client.py\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "async def make_request(url):\n",
    "    async with aiohttp.request('get', url) as resp:\n",
    "        print(await resp.read())\n",
    "\n",
    "\n",
    "\n",
    "tasks = [\n",
    "    loop.create_task(\n",
    "        make_request(\"http://127.0.0.1:5000\")\n",
    "    ) for _ in range(5)\n",
    "]\n",
    "\n",
    "start_time = datetime.now()\n",
    "await asyncio.wait(tasks)\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"took {elapsed_time.seconds} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapping\n",
    "- Sync: Blocking operations.\n",
    "- Concurrency: Making progress together.\n",
    "- Async: Non blocking operations.\n",
    "- Parallelism: Making progress in parallel.\n",
    "- locking: avoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "| feature/ library | threading | multiprocessing | asyncio |\n",
    "|------------------------|-----------------------------------------|-------------------|--------------------------------------------------|\n",
    "| scheduling | preemptive | preemptive | cooperative |\n",
    "| use multiple CPUs | no | yes | no |\n",
    "| scalability | medium (100s) | low (10s) | high (1000s) |\n",
    "| use blocking functions | yes | yes | no |\n",
    "| when to use | Existing codebase, I/O bound, blocking calls | CPU bound tasks |New codebase, I/O bound, large scale |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "- [python concurrency story](https://powerfulpython.com/blog/python-concurrency-story-pt1/)\n",
    "- [Python concurrency keynote - Raymond Hettinger](https://www.youtube.com/watch?v=9zinZmE3Ogk)\n",
    "[Python Concurrency From the Ground Up - David Beazley](https://www.youtube.com/watch?v=MCs5OvhV9S4)\n",
    "- [github repo for the talk](https://github.com/madhukar93/python_concurrency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
